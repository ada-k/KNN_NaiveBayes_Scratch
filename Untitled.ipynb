{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9db525a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import randrange\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfba9d10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "919ea765",
   "metadata": {},
   "source": [
    "## Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "155ca041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14, 3), (14,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 1 a) and 2 a) Training Data:\n",
    "x_train = np.array([\n",
    "    [1.6530190426733, 72.871146648479, 24],\n",
    "    [1.6471384909498, 72.612785314988, 34],\n",
    "    [1.6472055785348, 73.53968351051, 33],\n",
    "    [1.7323008914951, 76.067870338779, 30],\n",
    "    [1.6750702657911, 81.05582111533, 30],\n",
    "    [1.5780970716644, 64.926084680188, 30],\n",
    "    [1.6587629355524, 69.38092449041, 30],\n",
    "    [1.6763295980234, 77.062295990149, 31],\n",
    "    [1.7187224085504, 62.112923317057, 37],\n",
    "    [1.5202218226439, 66.151444019603, 27],\n",
    "    [1.5552689261884, 66.076386143769, 31],\n",
    "    [1.6969333189258, 77.45386244568, 34],\n",
    "    [1.6887980792886, 76.489640732464, 37],\n",
    "    [1.5213552893624, 63.952944947832, 35]\n",
    "], dtype=float)\n",
    "\n",
    "y_train = np.array([\"W\", \"W\", \"M\", \"M\", \"M\", \"W\", \"M\", \"M\", \"W\", \"W\", \"W\", \"M\", \"M\", \"W\"])\n",
    "# label encode: 0s:M, 1s:W\n",
    "y_train = np.array([\"1\", \"1\", \"0\", \"0\", \"0\", \"1\", \"0\", \"0\", \"1\", \"1\", \"1\", \"0\", \"0\", \"1\"], dtype=int)\n",
    "\n",
    "x_train = x_train.astype(float)\n",
    "y_train = y_train.astype(int)\n",
    "\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc791109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 1 a) and 2 a) Test Data:\n",
    "x_test = np.array([\n",
    "    [1.62065758929, 59.376557437583, 32],\n",
    "    [1.7793983848363, 72.071775670801, 36],\n",
    "    [1.7004576585974, 66.267508112786, 31],\n",
    "    [1.6591086215159, 61.751621901787, 29]\n",
    "], dtype=float)\n",
    "\n",
    "x_test = x_test.astype(float)\n",
    "\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22e5843b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 1 c, 1 d, 2 c, 2 d) Program Data\n",
    "# replaced F=1, M=0\n",
    "data = np.array([\n",
    "    [1.5963600450124, 75.717194178189, 23, 1],\n",
    "    [1.6990610819676, 83.477307503684, 25, 0],\n",
    "    [1.5052092436, 74.642420817737, 21, 1],\n",
    "    [1.5738635789008, 78.562465284603, 30, 0],\n",
    "    [1.796178772769, 74.566117057707, 29, 0],\n",
    "    [1.6274618774347, 82.250591567161, 21, 1],\n",
    "    [1.6396843250708, 71.37567170848, 20, 1],\n",
    "    [1.538505823668, 77.418902097029, 32, 1],\n",
    "    [1.6488692005889, 76.333044488477, 26, 1],\n",
    "    [1.7233804613095, 85.812112126306, 27, 0],\n",
    "    [1.7389100516771, 76.424421782215, 24, 1],\n",
    "    [1.5775696242624, 77.201404139171, 29, 1],\n",
    "    [1.7359417237856, 77.004988515324, 20, 0],\n",
    "    [1.5510482441354, 72.950756316157, 24, 1],\n",
    "    [1.5765653263667, 74.750113664457, 34, 1],\n",
    "    [1.4916026885377, 65.880438515643, 28, 1],\n",
    "    [1.6755053770068, 78.901754249459, 22, 0],\n",
    "    [1.4805881225567, 69.652364469244, 30, 1],\n",
    "    [1.6343943760912, 73.998278712613, 30, 1],\n",
    "    [1.6338449829543, 79.216500811112, 27, 1],\n",
    "    [1.5014451222259, 66.917339299419, 27, 1],\n",
    "    [1.8575887178701, 79.942454850988, 28, 0],\n",
    "    [1.6805940669394, 78.213519314007, 27, 1],\n",
    "    [1.6888905106948, 83.031099742808, 20, 0],\n",
    "    [1.7055120272359, 84.233282531303, 18, 0],\n",
    "    [1.5681965896812, 74.753880204215, 22, 1],\n",
    "    [1.6857758389206, 84.014217544019, 25, 1],\n",
    "    [1.7767370337678, 75.709336556562, 27, 0],\n",
    "    [1.6760125952287, 74.034126149139, 28, 0],\n",
    "    [1.5999112612548, 72.040030344184, 27, 0],\n",
    "    [1.6770845322305, 76.149431872551, 25, 0],\n",
    "    [1.7596128136991, 87.366395298795, 29, 0],\n",
    "    [1.5344541456027, 73.832214971449, 22, 1],\n",
    "    [1.5992629534387, 82.4806916967, 34, 1],\n",
    "    [1.6714162787917, 67.986534194515, 29, 1],\n",
    "    [1.7070831676329, 78.269583353177, 25, 0],\n",
    "    [1.5691295338456, 81.09431696972, 27, 0],\n",
    "    [1.7767893419281, 76.910413184648, 30, 0],\n",
    "    [1.5448153215763, 76.888087599642, 32, 1],\n",
    "    [1.5452842691008, 69.761889289463, 30, 1],\n",
    "    [1.6469991919639, 82.289126983444, 18, 1],\n",
    "    [1.6353732734723, 77.829257585654, 19, 1],\n",
    "    [1.7175342426502, 85.002276406574, 26, 0],\n",
    "    [1.6163551692382, 77.247935733799, 21, 0],\n",
    "    [1.6876845881843, 85.616829192322, 27, 0],\n",
    "    [1.5472705508274, 64.474350365634, 23, 1],\n",
    "    [1.558229415357, 80.382011318379, 21, 1],\n",
    "    [1.6242189230632, 69.567339939973, 28, 1],\n",
    "    [1.8215645865237, 78.163631826626, 22, 1],\n",
    "    [1.6984142478298, 69.884030497097, 26, 0],\n",
    "    [1.6468551415123, 82.666468220128, 29, 0],\n",
    "    [1.5727791290292, 75.545348033094, 24, 0],\n",
    "    [1.8086593470477, 78.093913654921, 27, 0],\n",
    "    [1.613966988578, 76.083586505149, 23, 1],\n",
    "    [1.6603990297076, 70.539053122611, 24, 0],\n",
    "    [1.6737443242383, 66.042005829182, 28, 1],\n",
    "    [1.6824912337281, 81.061984274536, 29, 0],\n",
    "    [1.5301691510101, 77.26547501308, 22, 0],\n",
    "    [1.7392340943261, 92.752488433153, 24, 0],\n",
    "    [1.6427105169884, 83.322790265985, 30, 0],\n",
    "    [1.5889040551166, 74.848224733663, 25, 1],\n",
    "    [1.5051718284868, 80.078271153645, 31, 1],\n",
    "    [1.729420786579, 81.936423109142, 26, 0],\n",
    "    [1.7352568354092, 85.497712687992, 19, 0],\n",
    "    [1.5056950011245, 73.726557750383, 24, 1],\n",
    "    [1.772404089054, 75.534265951718, 30, 0],\n",
    "    [1.5212346939173, 74.355845722315, 29, 1],\n",
    "    [1.8184515409355, 85.705767969326, 25, 0],\n",
    "    [1.7307897479464, 84.277029918205, 28, 1],\n",
    "    [1.6372690389158, 72.289040612489, 27, 0],\n",
    "    [1.6856953072545, 70.406532419182, 28, 1],\n",
    "    [1.832494802635, 81.627925524191, 27, 0],\n",
    "    [1.5061197864796, 85.886760677468, 31, 1],\n",
    "    [1.5970906671458, 71.755566818152, 27, 1],\n",
    "    [1.6780459059283, 78.900587239209, 25, 1],\n",
    "    [1.6356901170146, 84.066566323977, 21, 1],\n",
    "    [1.6085494116591, 70.950456539016, 30, 0],\n",
    "    [1.5873479102442, 77.558144903338, 25, 0],\n",
    "    [1.7542078120838, 75.3117550236, 26, 0],\n",
    "    [1.642417315747, 67.97377818999, 31, 1],\n",
    "    [1.5744266340913, 81.767568318602, 23, 0],\n",
    "    [1.8470601407979, 68.606183538532, 30, 1],\n",
    "    [1.7119387468283, 80.560922353487, 27, 1],\n",
    "    [1.6169930563306, 75.538611935125, 27, 0],\n",
    "    [1.6355653058986, 78.49626023408, 24, 0],\n",
    "    [1.6035395957618, 79.226052358485, 33, 0],\n",
    "    [1.662787957279, 76.865925681154, 25, 0],\n",
    "    [1.5889291137091, 76.548543553914, 28, 1],\n",
    "    [1.9058127964477, 82.56539915922, 25, 0],\n",
    "    [1.694633493614, 62.870480634419, 21, 1],\n",
    "    [1.7635692396034, 82.479783004684, 27, 0],\n",
    "    [1.6645292231449, 75.838104636904, 29, 1],\n",
    "    [1.7201968406129, 81.134689293557, 24, 1],\n",
    "    [1.5775563651749, 65.920103519266, 24, 1],\n",
    "    [1.6521294216004, 83.312640709417, 28, 0],\n",
    "    [1.5597501915973, 76.475667826389, 30, 1],\n",
    "    [1.7847561120027, 83.363676219109, 29, 0],\n",
    "    [1.6765690500715, 73.98959022721, 23, 0],\n",
    "    [1.6749260607992, 73.687015573315, 27, 1],\n",
    "    [1.58582362825, 71.713707691505, 28, 0],\n",
    "    [1.5893375739649, 74.248033504548, 27, 1],\n",
    "    [1.6084440045081, 71.126430164213, 27, 1],\n",
    "    [1.6048804804343, 82.049319162211, 26, 1],\n",
    "    [1.5774196609804, 70.878214496062, 24, 1],\n",
    "    [1.6799586185525, 75.649534976838, 29, 1],\n",
    "    [1.7315642636281, 92.12183674186, 29, 0],\n",
    "    [1.5563282000349, 69.312673560451, 32, 1],\n",
    "    [1.7784349641893, 83.464562543, 26, 0],\n",
    "    [1.7270244609765, 76.599791001341, 22, 1],\n",
    "    [1.6372540837311, 74.746741127229, 30, 1],\n",
    "    [1.582550559056, 73.440027907722, 23, 1],\n",
    "    [1.722864383186, 79.37821152354, 20, 1],\n",
    "    [1.5247544081009, 70.601290492141, 27, 1],\n",
    "    [1.580858666774, 70.146982323579, 24, 1],\n",
    "    [1.703343390074, 90.153276095421, 22, 1],\n",
    "    [1.5339948635367, 59.675627532338, 25, 1],\n",
    "    [1.8095306490733, 86.001187990639, 20, 0],\n",
    "    [1.7454786971676, 85.212429336602, 22, 0],\n",
    "    [1.6343303342105, 85.46378358014, 32, 0],\n",
    "    [1.5983479173071, 79.323905480504, 27, 1]\n",
    "])\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d681a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cbda0060",
   "metadata": {},
   "source": [
    "## K Nearest Neighbor\n",
    "\n",
    "1. Consider the problem where we want to predict the gender of a person from a set of input parameters,namely height, weight, and age."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a91981f",
   "metadata": {},
   "source": [
    "### a\n",
    "\n",
    "Using Cartesian distance, Manhattan distance and Minkowski distance of order 3 as the similarity measurements show the results of the gender prediction for the Evaluation data that is listed below generated training data for values of K of 1, 3, and 7. Include the intermediate steps (i.e., distance calculation, neighbor selection, and prediction).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9186a3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cartesian distance: k=1,3,7\n",
    "\n",
    "class KNearestNeighbors():\n",
    "    def __init__(self, X_train, y_train, n_neighbors=1, weights='uniform', distance=\"cartesian\"):\n",
    "\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.weights = weights\n",
    "\n",
    "        self.n_classes = 2\n",
    "        \n",
    "        self.distance = distance\n",
    "\n",
    "    # distance metrics\n",
    "    def cartesian_distance(self, a, b):\n",
    "        return np.sqrt(np.sum((a - b)**2, axis=1))\n",
    "    \n",
    "    def manhattan_distance(self, a, b):\n",
    "        return sum(abs(val1-val2) for val1, val2 in zip(a,b))\n",
    "\n",
    "    def minkowski_distance(a, b, p=3):\n",
    "        return np.sum(np.abs(a - b)**p, axis=1)**(1/p)\n",
    "\n",
    "    # neighnor selection\n",
    "    def kneighbors(self, X_test, return_distance=False):\n",
    "\n",
    "        dist = []\n",
    "        neigh_ind = []\n",
    "        \n",
    "        if self.distance == \"cartesian\":\n",
    "            point_dist = [self.cartesian_distance(x_test, self.X_train) for x_test in X_test]\n",
    "            \n",
    "        elif self.distance == \"manhattan\":\n",
    "            point_dist = [self.manhattan_distance(x_test, self.X_train) for x_test in X_test]\n",
    "            \n",
    "        elif self.distance == \"minkowski\":\n",
    "            point_dist = [self.minkowski_distance(x_test, self.X_train) for x_test in X_test]\n",
    "\n",
    "        for row in point_dist:\n",
    "            enum_neigh = enumerate(row)\n",
    "            sorted_neigh = sorted(enum_neigh,\n",
    "                                  key=lambda x: x[1])[:self.n_neighbors]\n",
    "\n",
    "            ind_list = [tup[0] for tup in sorted_neigh]\n",
    "            dist_list = [tup[1] for tup in sorted_neigh]\n",
    "\n",
    "            dist.append(dist_list)\n",
    "            neigh_ind.append(ind_list)\n",
    "\n",
    "        if return_distance:\n",
    "            return np.array(dist), np.array(neigh_ind)\n",
    "\n",
    "        return np.array(neigh_ind)\n",
    "\n",
    "    # prediction\n",
    "    def predict(self, X_test):\n",
    "\n",
    "        if self.weights == 'uniform':\n",
    "            neighbors = self.kneighbors(X_test)\n",
    "            y_pred = np.array([\n",
    "                np.argmax(np.bincount(self.y_train[neighbor]))\n",
    "                for neighbor in neighbors\n",
    "            ])\n",
    "\n",
    "            return y_pred\n",
    "\n",
    "        if self.weights == 'distance':\n",
    "\n",
    "            dist, neigh_ind = self.kneighbors(X_test, return_distance=True)\n",
    "\n",
    "            inv_dist = 1 / dist\n",
    "\n",
    "            mean_inv_dist = inv_dist / np.sum(inv_dist, axis=1)[:, np.newaxis]\n",
    "\n",
    "            proba = []\n",
    "\n",
    "            for i, row in enumerate(mean_inv_dist):\n",
    "\n",
    "                row_pred = self.y_train[neigh_ind[i]]\n",
    "\n",
    "                for k in range(self.n_classes):\n",
    "                    indices = np.where(row_pred == k)\n",
    "                    prob_ind = np.sum(row[indices])\n",
    "                    proba.append(np.array(prob_ind))\n",
    "\n",
    "            predict_proba = np.array(proba).reshape(X_test.shape[0],\n",
    "                                                    self.n_classes)\n",
    "\n",
    "            y_pred = np.array([np.argmax(item) for item in predict_proba])\n",
    "\n",
    "            return y_pred\n",
    "\n",
    "    # accuracy score\n",
    "    def score(self, X_test, y_test):\n",
    "        y_pred = self.predict(X_test)\n",
    "\n",
    "        return float(sum(y_pred == y_test)) / float(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bd39797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"minkowski distance: 1 neighbor\")\n",
    "# knn = KNearestNeighbors(x_train, y_train, n_neighbors=1, distance=\"minkowski\")\n",
    "# pred = knn.predict(x_test)\n",
    "# # undo the label encoding\n",
    "# print([\"F\" if x == 1 else \"M\" for x in pred])\n",
    "# print(\"-------------------------------\")\n",
    "\n",
    "\n",
    "# print(\"minkowski distance: 3 neighbors\")\n",
    "# knn = KNearestNeighbors(x_train, y_train, n_neighbors=3, distance=\"minkowski\")\n",
    "# pred = knn.predict(x_test)\n",
    "# # undo the label encoding\n",
    "# print([\"F\" if x == 1 else \"M\" for x in pred])\n",
    "# print(\"-------------------------------\")\n",
    "\n",
    "\n",
    "# print(\"minkowski distance: 7 neighbors\")\n",
    "# knn = KNearestNeighbors(x_train, y_train, n_neighbors=7, distance=\"minkowski\")\n",
    "# pred = knn.predict(x_test)\n",
    "# # undo the label encoding\n",
    "# print([\"F\" if x == 1 else \"M\" for x in pred])\n",
    "# print(\"-------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09042626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cartesian distance: 1 neighbor\n",
      "['F', 'F', 'F', 'F']\n",
      "-------------------------------\n",
      "cartesian distance: 3 neighbors\n",
      "['F', 'M', 'F', 'F']\n",
      "-------------------------------\n",
      "cartesian distance: 7 neighbors\n",
      "['F', 'M', 'F', 'F']\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"cartesian distance: 1 neighbor\")\n",
    "knn = KNearestNeighbors(x_train, y_train, n_neighbors=1, distance=\"cartesian\")\n",
    "pred = knn.predict(x_test)\n",
    "# undo the label encoding\n",
    "print([\"F\" if x == 1 else \"M\" for x in pred])\n",
    "print(\"-------------------------------\")\n",
    "\n",
    "\n",
    "print(\"cartesian distance: 3 neighbors\")\n",
    "knn = KNearestNeighbors(x_train, y_train, n_neighbors=3, distance=\"cartesian\")\n",
    "pred = knn.predict(x_test)\n",
    "# undo the label encoding\n",
    "print([\"F\" if x == 1 else \"M\" for x in pred])\n",
    "print(\"-------------------------------\")\n",
    "\n",
    "\n",
    "print(\"cartesian distance: 7 neighbors\")\n",
    "knn = KNearestNeighbors(x_train, y_train, n_neighbors=7, distance=\"cartesian\")\n",
    "pred = knn.predict(x_test)\n",
    "# undo the label encoding\n",
    "print([\"F\" if x == 1 else \"M\" for x in pred])\n",
    "print(\"-------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82f1b8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manhattan distance: 1 neighbor\n",
      "['M', 'M', 'M', 'M']\n",
      "-------------------------------\n",
      "manhattan distance: 3 neighbors\n",
      "['F', 'F', 'F', 'F']\n",
      "-------------------------------\n",
      "manhattan distance: 7 neighbors\n",
      "['F', 'F', 'F', 'F']\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"manhattan distance: 1 neighbor\")\n",
    "knn = KNearestNeighbors(x_train, y_train, n_neighbors=1, distance=\"manhattan\")\n",
    "pred = knn.predict(x_test)\n",
    "# undo the label encoding\n",
    "print([\"F\" if x == 1 else \"M\" for x in pred])\n",
    "print(\"-------------------------------\")\n",
    "\n",
    "\n",
    "print(\"manhattan distance: 3 neighbors\")\n",
    "knn = KNearestNeighbors(x_train, y_train, n_neighbors=3, distance=\"manhattan\")\n",
    "pred = knn.predict(x_test)\n",
    "# undo the label encoding\n",
    "print([\"F\" if x == 1 else \"M\" for x in pred])\n",
    "print(\"-------------------------------\")\n",
    "\n",
    "\n",
    "print(\"manhattan distance: 7 neighbors\")\n",
    "knn = KNearestNeighbors(x_train, y_train, n_neighbors=7, distance=\"manhattan\")\n",
    "pred = knn.predict(x_test)\n",
    "# undo the label encoding\n",
    "print([\"F\" if x == 1 else \"M\" for x in pred])\n",
    "print(\"-------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fe54fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8909ad3c",
   "metadata": {},
   "source": [
    "###    b. \n",
    "    \n",
    "Implement the KNN algorithm for this problem. Your implementation should work with different training data sets as well as different values of K and allow to input a data point for the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66fd028e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cartesian distance: k=1,3,7\n",
    "\n",
    "class KNearestNeighbors():\n",
    "    def __init__(self, X_train, y_train, n_neighbors=1, weights='uniform', distance=\"cartesian\"):\n",
    "\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.weights = weights\n",
    "\n",
    "        self.n_classes = 2\n",
    "        \n",
    "        self.distance = distance\n",
    "\n",
    "    # distance metrics\n",
    "    def cartesian_distance(self, a, b):\n",
    "        return np.sqrt(np.sum((a - b)**2, axis=1))\n",
    "    \n",
    "    def manhattan_distance(self, a, b):\n",
    "        return sum(abs(val1-val2) for val1, val2 in zip(a,b))\n",
    "\n",
    "    def minkowski_distance(a, b, p=3):\n",
    "        return np.sum(np.abs(a - b)**p, axis=1)**(1/p)\n",
    "\n",
    "    # neighnor selection\n",
    "    def kneighbors(self, X_test, return_distance=False):\n",
    "\n",
    "        dist = []\n",
    "        neigh_ind = []\n",
    "        \n",
    "        if self.distance == \"cartesian\":\n",
    "            point_dist = [self.cartesian_distance(x_test, self.X_train) for x_test in X_test]\n",
    "            \n",
    "        elif self.distance == \"manhattan\":\n",
    "            point_dist = [self.manhattan_distance(x_test, self.X_train) for x_test in X_test]\n",
    "            \n",
    "        elif self.distance == \"minkowski\":\n",
    "            point_dist = [self.minkowski_distance(x_test, self.X_train) for x_test in X_test]\n",
    "\n",
    "        for row in point_dist:\n",
    "            enum_neigh = enumerate(row)\n",
    "            sorted_neigh = sorted(enum_neigh,\n",
    "                                  key=lambda x: x[1])[:self.n_neighbors]\n",
    "\n",
    "            ind_list = [tup[0] for tup in sorted_neigh]\n",
    "            dist_list = [tup[1] for tup in sorted_neigh]\n",
    "\n",
    "            dist.append(dist_list)\n",
    "            neigh_ind.append(ind_list)\n",
    "\n",
    "        if return_distance:\n",
    "            return np.array(dist), np.array(neigh_ind)\n",
    "\n",
    "        return np.array(neigh_ind)\n",
    "\n",
    "    # prediction\n",
    "    def predict(self, X_test):\n",
    "\n",
    "        if self.weights == 'uniform':\n",
    "            neighbors = self.kneighbors(X_test)\n",
    "            y_pred = np.array([\n",
    "                np.argmax(np.bincount(self.y_train[neighbor]))\n",
    "                for neighbor in neighbors\n",
    "            ])\n",
    "\n",
    "            return y_pred\n",
    "\n",
    "        if self.weights == 'distance':\n",
    "\n",
    "            dist, neigh_ind = self.kneighbors(X_test, return_distance=True)\n",
    "\n",
    "            inv_dist = 1 / dist\n",
    "\n",
    "            mean_inv_dist = inv_dist / np.sum(inv_dist, axis=1)[:, np.newaxis]\n",
    "\n",
    "            proba = []\n",
    "\n",
    "            for i, row in enumerate(mean_inv_dist):\n",
    "\n",
    "                row_pred = self.y_train[neigh_ind[i]]\n",
    "\n",
    "                for k in range(self.n_classes):\n",
    "                    indices = np.where(row_pred == k)\n",
    "                    prob_ind = np.sum(row[indices])\n",
    "                    proba.append(np.array(prob_ind))\n",
    "\n",
    "            predict_proba = np.array(proba).reshape(X_test.shape[0],\n",
    "                                                    self.n_classes)\n",
    "\n",
    "            y_pred = np.array([np.argmax(item) for item in predict_proba])\n",
    "\n",
    "            return y_pred\n",
    "\n",
    "    # accuracy score\n",
    "    def score(self, X_test, y_test):\n",
    "        y_pred = self.predict(X_test)\n",
    "\n",
    "        return float(sum(y_pred == y_test)) / float(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb75ebb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "517de131",
   "metadata": {},
   "source": [
    "###    c. \n",
    "To evaluate the performance of the KNN algorithm (using Euclidean distance metric), implement a leave-one-out evaluation routine for your algorithm. In leave-one-out validation, we repeatedly evaluate the algorithm by removing one data point from the training set, training the algorithm on the remaining data set and then testing it on the point we removed to see if the label matches or not. Repeating this for each of the data points gives us an estimate as to the percentage of erroneous predictions the algorithm makes and thus a measure of the accuracy of the algorithm for the given data. Apply your leave-one-out validation with your KNN algorithm to the dataset for Question 1 c) for values for K of 1, 3, 5, 7, 9, and 11 and report the results. For which value of K do you get the best performance?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1b3fa4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class kNNClassifier:\n",
    "\n",
    "    def __init__(self,k = 3, distanceMetric = 'euclidean'):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, xTrain, yTrain):\n",
    "\n",
    "        assert len(xTrain) == len(yTrain)\n",
    "        self.trainData = xTrain\n",
    "        self.trainLabels = yTrain\n",
    "\n",
    "    def getNeighbors(self, testRow):\n",
    "        \n",
    "        calcDM = distanceMetrics()\n",
    "        distances = []\n",
    "        for i, trainRow in enumerate(self.trainData):\n",
    "            if self.distanceMetric == 'euclidean':\n",
    "                distances.append([trainRow, calcDM.euclideanDistance(testRow, trainRow), self.trainLabels[i]])\n",
    "            elif self.distanceMetric == 'manhattan':\n",
    "                distances.append([trainRow, calcDM.manhattanDistance(testRow, trainRow), self.trainLabels[i]])\n",
    "            elif self.distanceMetric == 'hamming':\n",
    "                distances.append([trainRow, calcDM.hammingDistance(testRow, trainRow), self.trainLabels[i]])\n",
    "            distances.sort(key=operator.itemgetter(1))\n",
    "\n",
    "        neighbors = []\n",
    "        for index in range(self.k):\n",
    "            neighbors.append(distances[index])\n",
    "        return neighbors\n",
    "        \n",
    "    def predict(self, xTest, k, distanceMetric):\n",
    "\n",
    "        self.testData = xTest\n",
    "        self.k = k\n",
    "        self.distanceMetric = distanceMetric\n",
    "        predictions = []\n",
    "        \n",
    "        for i, testCase in enumerate(self.testData):\n",
    "            neighbors = self.getNeighbors(testCase)\n",
    "            output= [row[-1] for row in neighbors]\n",
    "            prediction = max(set(output), key=output.count)\n",
    "            predictions.append(prediction)\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b623db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class distanceMetrics:\n",
    "\n",
    "    def euclideanDistance(self, vector1, vector2):\n",
    "\n",
    "        self.vectorA, self.vectorB = vector1, vector2\n",
    "        if len(self.vectorA) != len(self.vectorB):\n",
    "            raise ValueError(\"Undefined for sequences of unequal length.\")\n",
    "        distance = 0.0\n",
    "        for i in range(len(self.vectorA)-1):\n",
    "            distance += (self.vectorA[i] - self.vectorB[i])**2\n",
    "        return (distance)**0.5\n",
    "    \n",
    "\n",
    "def printMetrics(actual, predictions):\n",
    "\n",
    "    assert len(actual) == len(predictions)\n",
    "    correct = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == predictions[i]:\n",
    "            correct += 1\n",
    "    return (correct / float(len(actual)) * 100.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "729c7c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class kFoldCV:\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def crossValSplit(self, dataset, numFolds):\n",
    "\n",
    "        dataSplit = list()\n",
    "        dataCopy = list(dataset)\n",
    "        foldSize = int(len(dataset) / numFolds)\n",
    "        for _ in range(numFolds):\n",
    "            fold = list()\n",
    "            while len(fold) < foldSize:\n",
    "                index = randrange(len(dataCopy))\n",
    "                fold.append(dataCopy.pop(index))\n",
    "            dataSplit.append(fold)\n",
    "        return dataSplit\n",
    "    \n",
    "    \n",
    "    def kFCVEvaluate(self, dataset, numFolds, *args):\n",
    "\n",
    "        knn = kNNClassifier()\n",
    "        folds = self.crossValSplit(dataset, numFolds)\n",
    "        scores = list()\n",
    "        for fold in folds:\n",
    "            trainSet = list(folds)\n",
    "            trainSet.remove(fold)\n",
    "            trainSet = sum(trainSet, [])\n",
    "            testSet = list()\n",
    "            for row in fold:\n",
    "                rowCopy = list(row)\n",
    "                testSet.append(rowCopy)\n",
    "                \n",
    "            trainLabels = [row[-1] for row in trainSet]\n",
    "            trainSet = [train[:-1] for train in trainSet]\n",
    "            knn.fit(trainSet,trainLabels)\n",
    "            \n",
    "            actual = [row[-1] for row in testSet]\n",
    "            testSet = [test[:-1] for test in testSet]\n",
    "            \n",
    "            predicted = knn.predict(testSet, *args)\n",
    "            \n",
    "            accuracy = printMetrics(actual, predicted)\n",
    "            scores.append(accuracy)\n",
    "\n",
    "      \n",
    "        print('Maximum Accuracy: %3f%%' % max(scores))\n",
    "        print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "830547f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1\n",
      "Maximum Accuracy: 88.888889%\n",
      "Mean Accuracy: 62.393%\n",
      "---------------------------------------------------------------------------\n",
      "k=3\n",
      "Maximum Accuracy: 87.500000%\n",
      "Mean Accuracy: 71.429%\n",
      "---------------------------------------------------------------------------\n",
      "k=5\n",
      "Maximum Accuracy: 100.000000%\n",
      "Mean Accuracy: 65.179%\n",
      "---------------------------------------------------------------------------\n",
      "k=7\n",
      "Maximum Accuracy: 87.500000%\n",
      "Mean Accuracy: 58.036%\n",
      "---------------------------------------------------------------------------\n",
      "k=9\n",
      "Maximum Accuracy: 87.500000%\n",
      "Mean Accuracy: 62.500%\n",
      "---------------------------------------------------------------------------\n",
      "k=11\n",
      "Maximum Accuracy: 87.500000%\n",
      "Mean Accuracy: 58.036%\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "kfcv = kFoldCV()\n",
    "\n",
    "# data prep\n",
    "trainFeatures = []\n",
    "for row in data:\n",
    "    index = row[0:]\n",
    "    temp = [item for item in index]\n",
    "    trainFeatures.append(temp)\n",
    "\n",
    "# 1\n",
    "print(\"k=1\")\n",
    "kfcv.kFCVEvaluate(trainFeatures, 14, 1, 'euclidean')\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "\n",
    "# 3\n",
    "print(\"k=3\")\n",
    "kfcv.kFCVEvaluate(trainFeatures, 14, 3, 'euclidean')\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "\n",
    "# 5\n",
    "print(\"k=5\")\n",
    "kfcv.kFCVEvaluate(trainFeatures, 14, 5, 'euclidean')\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "\n",
    "# 7\n",
    "print(\"k=7\")\n",
    "kfcv.kFCVEvaluate(trainFeatures, 14, 7, 'euclidean')\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "\n",
    "# 9\n",
    "print(\"k=9\")\n",
    "kfcv.kFCVEvaluate(trainFeatures, 14, 9, 'euclidean')\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "\n",
    "# 11\n",
    "print(\"k=11\")\n",
    "kfcv.kFCVEvaluate(trainFeatures, 14, 11, 'euclidean')\n",
    "print(\"---------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ab3431",
   "metadata": {},
   "source": [
    "When k==1 or k==3, the accuracy is highest with a percentage score of 66.964%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586b8571",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "923d8541",
   "metadata": {},
   "source": [
    "    d. Repeat the prediction and validation you performed in Question 1 c) using KNN when the age data is removed (i.e. when only the height and weight features are used as part of the distance calculation in the KNN algorithm). Report the results and compare the performance without the age attribute with the ones from Question 1 c). Discuss the results. What do the results tell you about the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0cf1729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1\n",
      "Maximum Accuracy: 25.000000%\n",
      "Mean Accuracy: 5.357%\n",
      "---------------------------------------------------------------------------\n",
      "k=3\n",
      "Maximum Accuracy: 37.500000%\n",
      "Mean Accuracy: 10.714%\n",
      "---------------------------------------------------------------------------\n",
      "k=5\n",
      "Maximum Accuracy: 12.500000%\n",
      "Mean Accuracy: 3.571%\n",
      "---------------------------------------------------------------------------\n",
      "k=7\n",
      "Maximum Accuracy: 50.000000%\n",
      "Mean Accuracy: 8.036%\n",
      "---------------------------------------------------------------------------\n",
      "k=9\n",
      "Maximum Accuracy: 25.000000%\n",
      "Mean Accuracy: 7.143%\n",
      "---------------------------------------------------------------------------\n",
      "k=11\n",
      "Maximum Accuracy: 25.000000%\n",
      "Mean Accuracy: 8.929%\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "kfcv = kFoldCV()\n",
    "\n",
    "# data prep\n",
    "trainFeatures = []\n",
    "for row in data[:, :-1]:\n",
    "    index = row[0:]\n",
    "    temp = [item for item in index]\n",
    "    trainFeatures.append(temp)\n",
    "\n",
    "# 1\n",
    "print(\"k=1\")\n",
    "kfcv.kFCVEvaluate(trainFeatures, 14, 1, 'euclidean')\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "\n",
    "# 3\n",
    "print(\"k=3\")\n",
    "kfcv.kFCVEvaluate(trainFeatures, 14, 3, 'euclidean')\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "\n",
    "# 5\n",
    "print(\"k=5\")\n",
    "kfcv.kFCVEvaluate(trainFeatures, 14, 5, 'euclidean')\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "\n",
    "# 7\n",
    "print(\"k=7\")\n",
    "kfcv.kFCVEvaluate(trainFeatures, 14, 7, 'euclidean')\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "\n",
    "# 9\n",
    "print(\"k=9\")\n",
    "kfcv.kFCVEvaluate(trainFeatures, 14, 9, 'euclidean')\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "\n",
    "# 11\n",
    "print(\"k=11\")\n",
    "kfcv.kFCVEvaluate(trainFeatures, 14, 11, 'euclidean')\n",
    "print(\"---------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21266363",
   "metadata": {},
   "source": [
    "The model accuracy drops significantly with the highest accuracy when modeling without the age data being 12.5% with k == 11. This implies that age is significant to the model when predicting gender.\n",
    "A second observation is the fact that the highest value of k==1 has the highest accuracy unlike in the previous case where smaller values of k (==3 or ==5) revealed the highest accuracy. This could indicate the higher the number of features, the better chance of getting a high accuracy when the number of k-neighbors is small and vice versa.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5534f6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:scraper] *",
   "language": "python",
   "name": "conda-env-scraper-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "12px",
    "width": "262px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "277px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
